{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import csv\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load in our csv files\n",
    "#the location of these files may differ on your own device, so change address accordingly\n",
    "\n",
    "unaliveraw= pd.read_csv(\"./data/unalive_data.csv\")\n",
    "\n",
    "killraw= pd.read_csv(\"./data/kill_data.csv\")\n",
    "\n",
    "murderraw= pd.read_csv(\"./data/murder_data.csv\")\n",
    "\n",
    "suicideraw= pd.read_csv(\"./data/suicide_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>date</th>\n",
       "      <th>data</th>\n",
       "      <th>metadata</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>unalive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'op_a': 5298, 'op_b': 0, 'total': 5304}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unalive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'op_a': 241, 'op_b': 0, 'total': 244}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unalive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'op_a': 283, 'op_b': 0, 'total': 288}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unalive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'op_a': 198, 'op_b': 0, 'total': 201}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>unalive</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[]</td>\n",
       "      <td>{'op_a': 190, 'op_b': 0, 'total': 195}</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      word  date data                                  metadata error\n",
       "0  unalive   NaN   []  {'op_a': 5298, 'op_b': 0, 'total': 5304}   NaN\n",
       "1  unalive   NaN   []    {'op_a': 241, 'op_b': 0, 'total': 244}   NaN\n",
       "2  unalive   NaN   []    {'op_a': 283, 'op_b': 0, 'total': 288}   NaN\n",
       "3  unalive   NaN   []    {'op_a': 198, 'op_b': 0, 'total': 201}   NaN\n",
       "4  unalive   NaN   []    {'op_a': 190, 'op_b': 0, 'total': 195}   NaN"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unaliveraw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolating the data we gathered\n",
    "\n",
    "#getting rid of empty entries and unnecessary columns for unalive\n",
    "#dropping all columns except data\n",
    "unaliveraw= unaliveraw.drop(['word', 'date', 'metadata', 'error'], axis= 1) \n",
    "unaliveraw= unaliveraw.replace('nan', np.nan)\n",
    "unaliveraw= unaliveraw.dropna() #dropping nan values\n",
    "unaliveraw= unaliveraw[unaliveraw['data'] != '[]'] #removing empty data entries\n",
    "unaliveraw= unaliveraw.reset_index(drop=True) #resetting index for df\n",
    "\n",
    "#repeating for kill\n",
    "killraw= killraw.drop(['word', 'date', 'metadata', 'error'], axis= 1)\n",
    "killraw= killraw.replace('nan', np.nan)\n",
    "killraw= killraw.dropna()\n",
    "killraw= killraw[killraw['data'] != '[]']\n",
    "killraw= killraw.reset_index(drop=True)\n",
    "\n",
    "#repeating for murder\n",
    "murderraw= murderraw.drop(['word', 'date', 'metadata', 'error'], axis= 1)\n",
    "murderraw= murderraw.replace('nan', np.nan)\n",
    "murderraw= murderraw.dropna()\n",
    "murderraw= murderraw[murderraw['data'] != '[]']\n",
    "murderraw= murderraw.reset_index(drop=True)\n",
    "\n",
    "#repeating for suicide\n",
    "suicideraw= suicideraw.drop(['word', 'date', 'metadata', 'error'], axis= 1)\n",
    "suicideraw= suicideraw.replace('nan', np.nan)\n",
    "suicideraw= suicideraw.dropna()\n",
    "suicideraw= suicideraw[suicideraw['data'] != '[]']\n",
    "suicideraw= suicideraw.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a list of the data we got for unalive\n",
    "#after this point we can access the data to analyze it\n",
    "unalivedata=[]\n",
    "#combining all the dataframe data into one list\n",
    "for index, row in unaliveraw.iterrows():\n",
    "    entry= row['data']\n",
    "    entry= eval(entry)    \n",
    "    unalivedata+=entry\n",
    "    \n",
    "#as usual repeating the process for the other words\n",
    "killdata=[]\n",
    "for index, row in killraw.iterrows():\n",
    "    entry= row['data']\n",
    "    entry= eval(entry)    \n",
    "    killdata+=entry\n",
    "    \n",
    "murderdata=[]\n",
    "for index, row in murderraw.iterrows():\n",
    "    entry= row['data']\n",
    "    entry= eval(entry)    \n",
    "    murderdata+=entry\n",
    "    \n",
    "suicidedata=[]\n",
    "for index, row in suicideraw.iterrows():\n",
    "    entry= row['data']\n",
    "    entry= eval(entry)    \n",
    "    suicidedata+=entry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sorting by date, with numbers for each word\n",
    "def collectposts(data):\n",
    "    posts= {}\n",
    "    for item in data:\n",
    "        itemdate= item['created_utc']\n",
    "        text= item['title']+item['selftext']\n",
    "        posts.update({str(itemdate) : text})\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting post text by date for each of our words\n",
    "unaliveposts= collectposts(unalivedata)\n",
    "killposts= collectposts(killdata)\n",
    "murderposts= collectposts(murderdata)\n",
    "suicideposts= collectposts(suicidedata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to determine if two datetimes are on the same day\n",
    "#time1 represents a day within our vis range\n",
    "#time2 represents the timestamp from a post\n",
    "def sameday(time1, time2):\n",
    "    time1= str(time1).split(\" \")[0]\n",
    "    time2= pd.to_datetime(time2, unit='s')\n",
    "    time2= str(time2).split(\" \")[0]\n",
    "    \n",
    "    if time1==time2:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to count the number of posts \n",
    "# there are occuring on a specific day\n",
    "def postcount(posts, date):\n",
    "    count=0\n",
    "    for post in posts:\n",
    "        if sameday(date, post):\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to consolidate all post text from a\n",
    "# specific day into a list\n",
    "def textcollect(posts, date):\n",
    "    texts= []\n",
    "    for post in posts:\n",
    "        if sameday(date, post):\n",
    "            texts.append(posts[post])\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\annas\\AppData\\Local\\Temp\\ipykernel_22332\\1491395278.py:6: FutureWarning: The behavior of 'to_datetime' with 'unit' when parsing strings is deprecated. In a future version, strings will be parsed as datetime strings, matching the behavior without a 'unit'. To retain the old behavior, explicitly cast ints or floats to numeric type before calling to_datetime.\n",
      "  time2= pd.to_datetime(time2, unit='s')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m unalivecount\u001b[38;5;241m=\u001b[39m postcount(unaliveposts, date)\n\u001b[0;32m     13\u001b[0m killcount\u001b[38;5;241m=\u001b[39m postcount(killposts, date)\n\u001b[1;32m---> 14\u001b[0m murdercount\u001b[38;5;241m=\u001b[39m \u001b[43mpostcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmurderposts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m suicidecount\u001b[38;5;241m=\u001b[39m postcount(suicideposts, date)\n\u001b[0;32m     17\u001b[0m dictentry\u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m : date, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munalive\u001b[39m\u001b[38;5;124m'\u001b[39m : unalivecount, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkill\u001b[39m\u001b[38;5;124m'\u001b[39m : killcount, \n\u001b[0;32m     18\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmurder\u001b[39m\u001b[38;5;124m'\u001b[39m : murdercount, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuicide\u001b[39m\u001b[38;5;124m'\u001b[39m : suicidecount}\n",
      "Cell \u001b[1;32mIn[26], line 6\u001b[0m, in \u001b[0;36mpostcount\u001b[1;34m(posts, date)\u001b[0m\n\u001b[0;32m      4\u001b[0m count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m post \u001b[38;5;129;01min\u001b[39;00m posts:\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43msameday\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m      7\u001b[0m         count\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m count\n",
      "Cell \u001b[1;32mIn[25], line 6\u001b[0m, in \u001b[0;36msameday\u001b[1;34m(time1, time2)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msameday\u001b[39m(time1, time2):\n\u001b[0;32m      5\u001b[0m     time1\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(time1)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m----> 6\u001b[0m     time2\u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m     time2\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(time2)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time1\u001b[38;5;241m==\u001b[39mtime2:\n",
      "File \u001b[1;32mc:\\Users\\annas\\scraping-env\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1101\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1099\u001b[0m         result \u001b[38;5;241m=\u001b[39m convert_listlike(argc, \u001b[38;5;28mformat\u001b[39m)\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1101\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43marg\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, np\u001b[38;5;241m.\u001b[39mbool_):\n\u001b[0;32m   1103\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(result)  \u001b[38;5;66;03m# TODO: avoid this kludge.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\annas\\scraping-env\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:407\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    406\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot specify both format and unit\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 407\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to_datetime_with_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mndim\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marg must be a string, datetime, list, tuple, 1-d array, or Series\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\annas\\scraping-env\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:532\u001b[0m, in \u001b[0;36m_to_datetime_with_unit\u001b[1;34m(arg, unit, name, utc, errors)\u001b[0m\n\u001b[0;32m    530\u001b[0m     result \u001b[38;5;241m=\u001b[39m Index\u001b[38;5;241m.\u001b[39m_with_infer(arr, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 532\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mDatetimeIndex\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, DatetimeIndex):\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32mc:\\Users\\annas\\scraping-env\\Lib\\site-packages\\pandas\\core\\indexes\\datetimes.py:370\u001b[0m, in \u001b[0;36mDatetimeIndex.__new__\u001b[1;34m(cls, data, freq, tz, normalize, closed, ambiguous, dayfirst, yearfirst, dtype, copy, name)\u001b[0m\n\u001b[0;32m    367\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_simple_new(data, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m--> 370\u001b[0m dtarr \u001b[38;5;241m=\u001b[39m \u001b[43mDatetimeArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_sequence_not_strict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    373\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtz\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    375\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfreq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mambiguous\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mambiguous\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    379\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    380\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    381\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m copy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, (Index, ABCSeries)):\n",
      "File \u001b[1;32mc:\\Users\\annas\\scraping-env\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:388\u001b[0m, in \u001b[0;36mDatetimeArray._from_sequence_not_strict\u001b[1;34m(cls, data, dtype, copy, tz, freq, dayfirst, yearfirst, ambiguous)\u001b[0m\n\u001b[0;32m    386\u001b[0m data_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(subarr\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    387\u001b[0m data_dtype \u001b[38;5;241m=\u001b[39m tz_to_dtype(tz, data_unit)\n\u001b[1;32m--> 388\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_simple_new\u001b[49m\u001b[43m(\u001b[49m\u001b[43msubarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfreq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minferred_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m unit \u001b[38;5;241m!=\u001b[39m result\u001b[38;5;241m.\u001b[39munit:\n\u001b[0;32m    390\u001b[0m     \u001b[38;5;66;03m# If unit was specified in user-passed dtype, cast to it here\u001b[39;00m\n\u001b[0;32m    391\u001b[0m     result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mas_unit(unit)\n",
      "File \u001b[1;32mc:\\Users\\annas\\scraping-env\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:304\u001b[0m, in \u001b[0;36mDatetimeArray._simple_new\u001b[1;34m(cls, values, freq, dtype)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dtype\n\u001b[0;32m    303\u001b[0m \u001b[38;5;66;03m# error: Signature of \"_simple_new\" incompatible with supertype \"NDArrayBacked\"\u001b[39;00m\n\u001b[1;32m--> 304\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_simple_new\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[0;32m    306\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m    307\u001b[0m     values: npt\u001b[38;5;241m.\u001b[39mNDArray[np\u001b[38;5;241m.\u001b[39mdatetime64],\n\u001b[0;32m    308\u001b[0m     freq: BaseOffset \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m     dtype: np\u001b[38;5;241m.\u001b[39mdtype[np\u001b[38;5;241m.\u001b[39mdatetime64] \u001b[38;5;241m|\u001b[39m DatetimeTZDtype \u001b[38;5;241m=\u001b[39m DT64NS_DTYPE,\n\u001b[0;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[0;32m    311\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(values, np\u001b[38;5;241m.\u001b[39mndarray)\n\u001b[0;32m    312\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mM\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#generate timestamps for every day we are surveying\n",
    "#this will give us the keys for our definitive dataset\n",
    "daterange= pd.date_range(start ='12-31-2018', \n",
    "         end ='1-1-2025', freq ='24h')\n",
    "\n",
    "#initializing our dataset for counting number of posts\n",
    "data_definitive= []\n",
    "\n",
    "#create a list of dictionaries for the data\n",
    "for date in daterange:\n",
    "    #count up the number of posts for each word for each day\n",
    "    unalivecount= postcount(unaliveposts, date)\n",
    "    killcount= postcount(killposts, date)\n",
    "    murdercount= postcount(murderposts, date)\n",
    "    suicidecount= postcount(suicideposts, date)\n",
    "    \n",
    "    #collect together the text from each day for each word\n",
    "    unalivetext= textcollect(unaliveposts, date)\n",
    "    killtext= textcollect(killposts, date)\n",
    "    murdertext= textcollect(murderposts, date)\n",
    "    suicidetext= textcollect(suicideposts, date)\n",
    "    \n",
    "    #compile all the information into a dictionary\n",
    "    dictentry= {'date' : date, \n",
    "                'unalive' : unalivecount, 'unalive_text' : unalivetext, \n",
    "                'kill' : killcount, 'kill_text' : killtext,\n",
    "                'murder' : murdercount, 'murder_text' : murdertext, \n",
    "                'suicide' : suicidecount, 'suicide_text' : suicidetext}\n",
    "    \n",
    "    #add this dictionary to data_definitive\n",
    "    data_definitive.append(dictentry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export our cleaned data into a csv so we can use it for vis\n",
    "\n",
    "#define our headers (column names)\n",
    "header = [\"date\", \"unalive\", \"unalive_text\", \n",
    "          \"kill\", \"kill_text\", \"murder\", \"murder_text\",\n",
    "          \"suicide\", \"suicide_text\"]\n",
    "\n",
    "#send to csv\n",
    "with open('cleaned_data.csv', 'w', encoding=\"utf-8\", newline='') as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=header)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data_definitive)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scraping-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
